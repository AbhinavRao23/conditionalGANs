{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AoOS2o2lwjk",
        "outputId": "33215832-dd22-4e94-c50d-6b1f8b499314"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Standard Libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle \n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "# Neural Network Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import make_grid\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import scipy.linalg as linalg\n",
        "\n",
        "#for colab purposes only\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize([0.5], [0.5]) \n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST('./data', \n",
        "                               train=True, \n",
        "                               download=True, \n",
        "                               transform=transform)\n",
        "\n",
        "validation_dataset = datasets.MNIST('./data', \n",
        "                                    train=False, \n",
        "                                    transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, \n",
        "                                                batch_size=batch_size, \n",
        "                                                shuffle=False)\n"
      ],
      "metadata": {
        "id": "TY2MxkrKnngO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (X_train, y_train) in train_loader:\n",
        "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
        "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThwzgC_GnrmN",
        "outputId": "e5ec7e1e-092d-4a1b-e140-99513ced5a2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: torch.Size([32, 1, 28, 28]) type: torch.FloatTensor\n",
            "y_train: torch.Size([32]) type: torch.LongTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Courtesy https://github.com/CSCfi/machine-learning-scripts.git\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 50)\n",
        "        self.fc1_drop = nn.Dropout(0.2)\n",
        "        self.fc2 = nn.Linear(50, 50)\n",
        "        self.fc2_drop = nn.Dropout(0.2)\n",
        "        self.fc3 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc1_drop(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc2_drop(x)\n",
        "        return F.log_softmax(self.fc3(x), dim=1)\n",
        "\n",
        "model = Net().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "N42eHZken3ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch, log_interval=200):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        optimizer.zero_grad() \n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "7HIGrb7on7Zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(loss_vector, accuracy_vector):\n",
        "    model.eval()\n",
        "    val_loss, correct = 0, 0\n",
        "    for data, target in validation_loader:\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        output = model(data)\n",
        "        val_loss += criterion(output, target).data.item()\n",
        "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data).cpu().sum()\n",
        "\n",
        "    val_loss /= len(validation_loader)\n",
        "    loss_vector.append(val_loss)\n",
        "\n",
        "    accuracy = 100. * correct.to(torch.float32) / len(validation_loader.dataset)\n",
        "    accuracy_vector.append(accuracy)\n",
        "    \n",
        "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        val_loss, correct, len(validation_loader.dataset), accuracy))"
      ],
      "metadata": {
        "id": "W9d4HnudoBFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "epochs = 10\n",
        "\n",
        "lossv, accv = [], []\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(epoch)\n",
        "    validate(lossv, accv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ym8j0Wt9oLq2",
        "outputId": "a1d328f7-89a9-468c-c4a6-e32c0b0edf4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation set: Average loss: 0.2976, Accuracy: 9121/10000 (91%)\n",
            "\n",
            "\n",
            "Validation set: Average loss: 0.2293, Accuracy: 9304/10000 (93%)\n",
            "\n",
            "\n",
            "Validation set: Average loss: 0.1959, Accuracy: 9389/10000 (94%)\n",
            "\n",
            "\n",
            "Validation set: Average loss: 0.1643, Accuracy: 9470/10000 (95%)\n",
            "\n",
            "\n",
            "Validation set: Average loss: 0.1547, Accuracy: 9509/10000 (95%)\n",
            "\n",
            "\n",
            "Validation set: Average loss: 0.1400, Accuracy: 9558/10000 (96%)\n",
            "\n",
            "\n",
            "Validation set: Average loss: 0.1342, Accuracy: 9578/10000 (96%)\n",
            "\n",
            "\n",
            "Validation set: Average loss: 0.1282, Accuracy: 9604/10000 (96%)\n",
            "\n",
            "\n",
            "Validation set: Average loss: 0.1307, Accuracy: 9594/10000 (96%)\n",
            "\n",
            "\n",
            "Validation set: Average loss: 0.1273, Accuracy: 9597/10000 (96%)\n",
            "\n",
            "CPU times: user 4min 13s, sys: 701 ms, total: 4min 14s\n",
            "Wall time: 4min 18s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelPath = '/content/gdrive/MyDrive/Colab Notebooks/GAN'\n",
        "modelfile = open(os.path.join(modelPath,'mnistModel.pkl'), 'wb')\n",
        "pickle.dump(model, modelfile)\n",
        "modelfile.close()"
      ],
      "metadata": {
        "id": "4EU-fcNzsApw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z8Ul6sdvz14K"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}